{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = pd.read_stata('./dataset/classifications_data/location.dta')\n",
    "df_data_class = pd.read_stata('./dataset/classifications_data/sitc_product.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './dataset/dataverse_files/'\n",
    "country_partner_sitc_4digit = 'country_partner_sitcproduct4digit_year_{}.csv'\n",
    "country_partner_sitc_2digit = 'country_partner_sitcproduct2digit_year.csv'\n",
    "country_partner_sitc_section = 'country_partner_sitcproductsection_year.csv'\n",
    "country_sitc_2digit = 'country_sitcproduct2digit_year.csv'\n",
    "country_sitc_4digit = 'country_sitcproduct4digit_year.csv'\n",
    "country_sitc_section = 'country_sitcproductsection_year.csv'\n",
    "sitc_2digit=2\n",
    "sitc_4digit=4\n",
    "\n",
    "def get_data(country_partner=True, sitc_digit=4, year=2019):\n",
    "    \"\"\"\n",
    "    Creates a Dataframe for a specified SITC dataset\n",
    "\n",
    "    Args:\n",
    "        country_partner: If True, dataset with trades between countries and partners are selected\n",
    "        sitc_digit: 4 for SITC-4 digit products, 2 for SITC-2 digit products, otw SITC product section\n",
    "        year: Year between 1962 and 2019 for the country-partner SITC-4 digit products\n",
    "    Returns:\n",
    "        Dataframe of the selected dataset\n",
    "    \"\"\"\n",
    "    path = folder_path\n",
    "    if country_partner:\n",
    "        if sitc_digit==sitc_4digit:\n",
    "            path += country_partner_sitc_4digit.format(year)\n",
    "        elif sitc_digit==sitc_2digit:\n",
    "            path += country_partner_sitc_2digit\n",
    "        else:\n",
    "            path += country_partner_sitc_section\n",
    "    else:\n",
    "        if sitc_digit==sitc_4digit:\n",
    "            path += country_sitc_4digit\n",
    "        elif sitc_digit==sitc_2digit:\n",
    "            path += country_sitc_2digit\n",
    "        else:\n",
    "            path += country_sitc_section\n",
    "\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('./dataset/classifications_data/ne_110m_admin_0_countries.geojson')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_country_codes(name):\n",
    "    if name == \"France\":\n",
    "        return [\"FR\",\"FRA\"]\n",
    "    elif name == \"Norway\":\n",
    "        return [\"NO\",\"NOR\"]\n",
    "    elif name == \"Kosovo\":\n",
    "        return [\"XK\",\"XKX\"]        \n",
    "    else:\n",
    "        if name != \"Northern Cyprus\" and name != \"Somaliland\":\n",
    "            print(name)\n",
    "        return [\"-99\",\"-99\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "result = {}\n",
    "Product_id = 0 #Change this variable to filter based on product types\n",
    "for YEAR in range(1962, 2020):\n",
    "    df_2019 = get_data(year=YEAR)\n",
    "    \n",
    "    product_parents = {}\n",
    "    for idx, row in df_data_class.iterrows():\n",
    "        key = row.product_id\n",
    "        product_id = key\n",
    "        parent_id = row.parent_id\n",
    "        while(product_id > 10):\n",
    "            row = df_data_class[df_data_class.product_id == parent_id].iloc[[0]]\n",
    "            product_id = row.product_id.item()\n",
    "            parent_id  = row.parent_id.item()        \n",
    "\n",
    "        product_parents[key] = product_id\n",
    "    \n",
    "    df_2019.product_id = df_2019.product_id.map(product_parents)\n",
    "    df_2019 = df_2019.drop(df_2019[df_2019.product_id != Product_id].index) \n",
    "    \n",
    "    \n",
    "    countries = pd.read_csv('./dataset/classifications_data/countries.csv') \n",
    "    countries = countries.rename(columns={\"country\": \"ISO_A2\"})\n",
    "    countries[\"ISO_A3\"] = 0\n",
    "    for i in data[\"features\"]: \n",
    "        if i[\"properties\"][\"ISO_A3\"] == \"-99\":\n",
    "            a2, a3 = fix_country_codes(i[\"properties\"][\"ADMIN\"])\n",
    "            countries.loc[countries.ISO_A2 == a2, 'ISO_A3'] = a3        \n",
    "        else:\n",
    "            countries.loc[countries.ISO_A2 == i[\"properties\"][\"ISO_A2\"], 'ISO_A3'] = i[\"properties\"][\"ISO_A3\"]\n",
    "    countries = countries.drop(countries[countries.ISO_A3 == 0].index)\n",
    "    countries[\"location_id\"] = -1\n",
    "    for index, row in df_location.iterrows():    \n",
    "        countries.loc[countries.ISO_A3 == row['location_code'], 'location_id'] = row['location_id']\n",
    "        countries.loc[countries.ISO_A3 == row['location_code'], 'name'] = row['location_name_short_en']\n",
    "    countries[countries.location_id == -1]\n",
    "    data_df = df_2019.drop([\"product_id\",\"year\",\"sitc_eci\",\"sitc_coi\",\"location_code\",\"partner_code\",\"sitc_product_code\"],axis = 1)\n",
    "    data_df = data_df.groupby([\"location_id\",\"partner_id\"], sort=True).sum().reset_index()\n",
    "    data_df = data_df.drop(data_df[~data_df.location_id.isin(countries.location_id)].index)\n",
    "    data_df = data_df.drop(data_df[~data_df.partner_id.isin(countries.location_id)].index)\n",
    "    \n",
    "    temp = {}\n",
    "    for mode in [\"import_value\",\"export_value\"]:\n",
    "        dummy = data_df.groupby('location_id').apply(lambda x : x.nlargest(20, mode)).reset_index(drop = True)\n",
    "        if mode == \"import_value\":\n",
    "            dummy = dummy.drop(\"export_value\",axis = 1)\n",
    "        else:\n",
    "            dummy = dummy.drop(\"import_value\",axis = 1)\n",
    "        dummy = dummy.astype({\"location_id\": str})\n",
    "        dummy = dummy.astype({\"partner_id\": str})\n",
    "        dummy[\"main_code\"] = -1\n",
    "        dummy[\"main_name\"] = -1\n",
    "#         dummy[\"main_lat\"] = -1\n",
    "#         dummy[\"main_lon\"] = -1\n",
    "        dummy[\"partner_code\"] = -1\n",
    "        dummy[\"partner_name\"] = -1\n",
    "#         dummy[\"partner_lat\"] = -1\n",
    "#         dummy[\"partner_lon\"] = -1\n",
    "\n",
    "        for index, row in countries.iterrows():    \n",
    "            dummy.loc[dummy.location_id == row['location_id'], 'main_code'] = row['ISO_A2']\n",
    "#             dummy.loc[dummy.location_id == str(row['location_id']), 'main_lat'] = row['latitude']\n",
    "#             dummy.loc[dummy.location_id == str(row['location_id']), 'main_lon'] = row['longitude']\n",
    "            dummy.loc[dummy.location_id == str(row['location_id']), 'main_name'] = row['name']\n",
    "\n",
    "            dummy.loc[dummy.partner_id == str(row['location_id']), 'partner_code'] = row['ISO_A2']\n",
    "#             dummy.loc[dummy.partner_id == str(row['location_id']), 'partner_lat'] = row['latitude']\n",
    "#             dummy.loc[dummy.partner_id == str(row['location_id']), 'partner_lon'] = row['longitude']\n",
    "            dummy.loc[dummy.partner_id == str(row['location_id']), 'partner_name'] = row['name']\n",
    "\n",
    "        dummy = dummy.drop([\"location_id\",\"partner_id\"],axis = 1)  \n",
    "        #Add percentage for opacity\n",
    "        sums = dummy.groupby(\"main_code\")[mode].sum()\n",
    "        dummy[\"percentage\"] = -1\n",
    "        for index, row in dummy.iterrows():\n",
    "             dummy.loc[index, \"percentage\"] = row[mode] / sums[row[\"main_code\"]]\n",
    "          \n",
    "        dummy = dummy.fillna(0)\n",
    "        for code in dummy.main_code.unique():\n",
    "            if  code not in temp:\n",
    "                temp[code] = {}\n",
    "            temp[code][mode] = dummy[dummy.main_code == code].to_numpy().tolist()\n",
    "    \n",
    "    result[YEAR] = temp\n",
    "    if YEAR % 10 == 0:\n",
    "        print(YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trade_data.json\", \"w\") as outfile:\n",
    "    json.dump(result, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'geo_export.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_11804/499625141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Opening JSON file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"geo_export.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# returns JSON object as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# a dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'geo_export.json'"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "f = open(\"geo_export.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open(\"trade_data.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data2 = json.load(f)\n",
    "f.close() \n",
    "data2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"2019\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"2019\"][\"AFG\"][\"export_value\"] == data[\"AFG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"2019\"][\"AFG\"][\"export_value\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"AFG\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,i in enumerate(data2[\"2000\"].values()):\n",
    "    if idx == 32150:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data2[\"2000\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"trade_data.json\", \"r\")\n",
    "jsonstr = f.read()\n",
    "jsonstr[32151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonstr[32000:32160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d643e56c8356b332e138988d3326f90faf1438da2687a45045158120a5c71be7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
