{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = pd.read_stata('../dataset/classifications_data/location.dta')\n",
    "df_data_class = pd.read_stata('../dataset/classifications_data/sitc_product.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../dataset/dataverse_files/'\n",
    "country_partner_sitc_4digit = 'country_partner_sitcproduct4digit_year_{}.csv'\n",
    "country_partner_sitc_2digit = 'country_partner_sitcproduct2digit_year.csv'\n",
    "country_partner_sitc_section = 'country_partner_sitcproductsection_year.csv'\n",
    "country_sitc_2digit = 'country_sitcproduct2digit_year.csv'\n",
    "country_sitc_4digit = 'country_sitcproduct4digit_year.csv'\n",
    "country_sitc_section = 'country_sitcproductsection_year.csv'\n",
    "sitc_2digit=2\n",
    "sitc_4digit=4\n",
    "\n",
    "def get_data(country_partner=True, sitc_digit=4, year=2019):\n",
    "    \"\"\"\n",
    "    Creates a Dataframe for a specified SITC dataset\n",
    "\n",
    "    Args:\n",
    "        country_partner: If True, dataset with trades between countries and partners are selected\n",
    "        sitc_digit: 4 for SITC-4 digit products, 2 for SITC-2 digit products, otw SITC product section\n",
    "        year: Year between 1962 and 2019 for the country-partner SITC-4 digit products\n",
    "    Returns:\n",
    "        Dataframe of the selected dataset\n",
    "    \"\"\"\n",
    "    path = folder_path\n",
    "    if country_partner:\n",
    "        if sitc_digit==sitc_4digit:\n",
    "            path += country_partner_sitc_4digit.format(year)\n",
    "        elif sitc_digit==sitc_2digit:\n",
    "            path += country_partner_sitc_2digit\n",
    "        else:\n",
    "            path += country_partner_sitc_section\n",
    "    else:\n",
    "        if sitc_digit==sitc_4digit:\n",
    "            path += country_sitc_4digit\n",
    "        elif sitc_digit==sitc_2digit:\n",
    "            path += country_sitc_2digit\n",
    "        else:\n",
    "            path += country_sitc_section\n",
    "\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('../dataset/classifications_data/ne_110m_admin_0_countries.geojson')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_country_codes(name):\n",
    "    if name == \"France\":\n",
    "        return [\"FR\",\"FRA\"]\n",
    "    elif name == \"Norway\":\n",
    "        return [\"NO\",\"NOR\"]\n",
    "    elif name == \"Kosovo\":\n",
    "        return [\"XK\",\"XKX\"]        \n",
    "    else:\n",
    "        if name != \"Northern Cyprus\" and name != \"Somaliland\":\n",
    "            print(name)\n",
    "        return [\"-99\",\"-99\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:58: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3361: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for YEAR in range(1962, 2020):\n",
    "    df_2019 = get_data(year=YEAR)\n",
    "    countries = pd.read_csv('../dataset/classifications_data/countries.csv') \n",
    "    countries = countries.rename(columns={\"country\": \"ISO_A2\"})\n",
    "    countries[\"ISO_A3\"] = 0\n",
    "    for i in data[\"features\"]: \n",
    "        if i[\"properties\"][\"ISO_A3\"] == \"-99\":\n",
    "            a2, a3 = fix_country_codes(i[\"properties\"][\"ADMIN\"])\n",
    "            countries.loc[countries.ISO_A2 == a2, 'ISO_A3'] = a3        \n",
    "        else:\n",
    "            countries.loc[countries.ISO_A2 == i[\"properties\"][\"ISO_A2\"], 'ISO_A3'] = i[\"properties\"][\"ISO_A3\"]\n",
    "    countries = countries.drop(countries[countries.ISO_A3 == 0].index)\n",
    "    countries[\"location_id\"] = -1\n",
    "    for index, row in df_location.iterrows():    \n",
    "        countries.loc[countries.ISO_A3 == row['location_code'], 'location_id'] = row['location_id']\n",
    "        countries.loc[countries.ISO_A3 == row['location_code'], 'name'] = row['location_name_short_en']\n",
    "    countries[countries.location_id == -1]\n",
    "    data_df = df_2019.drop([\"product_id\",\"year\",\"sitc_eci\",\"sitc_coi\",\"location_code\",\"partner_code\",\"sitc_product_code\"],axis = 1)\n",
    "    data_df = data_df.groupby([\"location_id\",\"partner_id\"], sort=True).sum().reset_index()\n",
    "    data_df = data_df.drop(data_df[~data_df.location_id.isin(countries.location_id)].index)\n",
    "    data_df = data_df.drop(data_df[~data_df.partner_id.isin(countries.location_id)].index)\n",
    "    \n",
    "    temp = {}\n",
    "    for mode in [\"import_value\",\"export_value\"]:\n",
    "        dummy = data_df.groupby('location_id').apply(lambda x : x.nlargest(20, mode)).reset_index(drop = True)\n",
    "        if mode == \"import_value\":\n",
    "            dummy = dummy.drop(\"export_value\",axis = 1)\n",
    "        else:\n",
    "            dummy = dummy.drop(\"import_value\",axis = 1)\n",
    "        dummy = dummy.astype({\"location_id\": str})\n",
    "        dummy = dummy.astype({\"partner_id\": str})\n",
    "        dummy[\"main_code\"] = -1\n",
    "        dummy[\"main_name\"] = -1\n",
    "#         dummy[\"main_lat\"] = -1\n",
    "#         dummy[\"main_lon\"] = -1\n",
    "        dummy[\"partner_code\"] = -1\n",
    "        dummy[\"partner_name\"] = -1\n",
    "#         dummy[\"partner_lat\"] = -1\n",
    "#         dummy[\"partner_lon\"] = -1\n",
    "\n",
    "        for index, row in countries.iterrows():    \n",
    "            dummy.loc[dummy.location_id == row['location_id'], 'main_code'] = row['ISO_A2']\n",
    "#             dummy.loc[dummy.location_id == str(row['location_id']), 'main_lat'] = row['latitude']\n",
    "#             dummy.loc[dummy.location_id == str(row['location_id']), 'main_lon'] = row['longitude']\n",
    "            dummy.loc[dummy.location_id == str(row['location_id']), 'main_name'] = row['name']\n",
    "\n",
    "            dummy.loc[dummy.partner_id == str(row['location_id']), 'partner_code'] = row['ISO_A2']\n",
    "#             dummy.loc[dummy.partner_id == str(row['location_id']), 'partner_lat'] = row['latitude']\n",
    "#             dummy.loc[dummy.partner_id == str(row['location_id']), 'partner_lon'] = row['longitude']\n",
    "            dummy.loc[dummy.partner_id == str(row['location_id']), 'partner_name'] = row['name']\n",
    "\n",
    "        dummy = dummy.drop([\"location_id\",\"partner_id\"],axis = 1)  \n",
    "        #Add percentage for opacity\n",
    "        sums = dummy.groupby(\"main_code\")[mode].sum()\n",
    "        dummy[\"percentage\"] = -1\n",
    "        for index, row in dummy.iterrows():\n",
    "             dummy.loc[index, \"percentage\"] = row[mode] / sums[row[\"main_code\"]]\n",
    "          \n",
    "        dummy = dummy.fillna(0)\n",
    "        for code in dummy.main_code.unique():\n",
    "            if  code not in temp:\n",
    "                temp[code] = {}\n",
    "            temp[code][mode] = dummy[dummy.main_code == code].to_numpy().tolist()\n",
    "    \n",
    "    result[YEAR] = temp\n",
    "    if YEAR % 10 == 0:\n",
    "        print(YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trade_data.json\", \"w\") as outfile:\n",
    "    json.dump(result, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open(\"geo_export.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATA', 'ATF', 'AUS', 'AUT', 'AZE', 'BDI', 'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', 'BRA', 'BRN', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', 'COD', 'COG', 'COL', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESH', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', 'FLK', 'FRA', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRL', 'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', 'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KOR', 'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LKA', 'LSO', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', 'MDG', 'MEX', 'MKD', 'MLI', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', 'MWI', 'MYS', 'NCL', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', 'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'PSE', 'QAT', 'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SLB', 'SLE', 'SLV', 'SOM', 'SRB', 'SUR', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', 'TKM', 'TLS', 'TTO', 'TUN', 'TUR', 'TZA', 'UGA', 'UKR', 'URY', 'USA', 'UZB', 'VEN', 'VNM', 'VUT', 'YEM', 'ZAF', 'ZMB', 'ZWE', 'TWN'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1962', '1963', '1964', '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "f = open(\"trade_data.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data2 = json.load(f)\n",
    "f.close() \n",
    "data2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AF', 'AO', 'AL', 'AE', 'AR', 'AM', 'AQ', 'TF', 'AU', 'AT', 'AZ', 'BI', 'BE', 'BJ', 'BF', 'BD', 'BG', 'BS', 'BA', 'BY', 'BZ', 'BO', 'BR', 'BN', 'BT', 'BW', 'CF', 'CA', 'CH', 'CL', 'CN', 'CI', 'CM', 'CD', 'CG', 'CO', 'CR', 'CU', 'CY', 'CZ', 'DE', 'DJ', 'DK', 'DO', 'DZ', 'EC', 'EG', 'ER', 'EH', 'ES', 'EE', 'ET', 'FI', 'FJ', 'FK', 'FR', 'GA', 'GB', 'GE', 'GH', 'GN', 'GM', 'GW', 'GQ', 'GR', 'GL', 'GT', 'GY', 'HN', 'HR', 'HT', 'HU', 'ID', 'IN', 'IE', 'IR', 'IQ', 'IS', 'IL', 'IT', 'JM', 'JO', 'JP', 'KZ', 'KE', 'KG', 'KH', 'KR', 'KW', 'LA', 'LB', 'LR', 'LY', 'LK', 'LS', 'LT', 'LU', 'LV', 'MA', 'MD', 'MG', 'MX', 'MK', 'ML', 'MM', 'ME', 'MN', 'MZ', 'MR', 'MW', 'MY', 'NC', 'NE', 'NG', 'NI', 'NL', 'NO', 'NP', 'NZ', 'OM', 'PK', 'PA', 'PE', 'PH', 'PG', 'PL', 'KP', 'PT', 'PY', 'PS', 'QA', 'RO', 'RU', 'RW', 'SA', 'SD', 'SN', 'SB', 'SL', 'SV', 'SO', 'RS', 'SR', 'SK', 'SI', 'SE', 'SZ', 'SY', 'TD', 'TG', 'TH', 'TJ', 'TM', 'TL', 'TT', 'TN', 'TR', 'TZ', 'UG', 'UA', 'UY', 'US', 'UZ', 'VE', 'VN', 'VU', 'YE', 'ZA', 'ZM', 'ZW', 'TW'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[\"2019\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AFG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_15172/3807321984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"2019\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AFG\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"export_value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AFG\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'AFG'"
     ]
    }
   ],
   "source": [
    "data2[\"2019\"][\"AFG\"][\"export_value\"] == data[\"AFG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"2019\"][\"AFG\"][\"export_value\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"AFG\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,i in enumerate(data2[\"2000\"].values()):\n",
    "    if idx == 32150:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data2[\"2000\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"trade_data.json\", \"r\")\n",
    "jsonstr = f.read()\n",
    "jsonstr[32151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonstr[32000:32160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d643e56c8356b332e138988d3326f90faf1438da2687a45045158120a5c71be7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
